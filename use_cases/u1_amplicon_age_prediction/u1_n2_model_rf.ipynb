{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Usecase 1: Age prediction run model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook can be run in the following conda environment:\n",
        "```shell\n",
        "\n",
        "# TODO: update instructions to remove local once ritme on conda\n",
        "mamba create -n ritme_model -c local -c qiime2 -c conda-forge -c bioconda -c pytorch -c anaconda -c defaults ritme ipykernel -y\n",
        "conda activate ritme_model\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ritme.find_best_model_config import (\n",
        "    _load_experiment_config,\n",
        "    _load_phylogeny,\n",
        "    _load_taxonomy,\n",
        "    find_best_model_config,\n",
        ")\n",
        "from ritme.split_train_test import _load_data, split_train_test\n",
        "from ritme.evaluate_tuned_models import evaluate_tuned_models\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "######## USER INPUTS ########\n",
        "# set experiment configuration path\n",
        "model_config_path = \"u1_rf_config.json\"\n",
        "\n",
        "# define path to feature table, metadata, phylogeny, and taxonomy\n",
        "path_to_ft = \"../../data/u1_subramanian14/otu_table_subr14_rar.tsv\"\n",
        "path_to_md = \"../../data/u1_subramanian14/md_subr14.tsv\"\n",
        "path_to_phylo = \"../../data/u1_subramanian14/fasttree_tree_rooted_subr14.qza\"\n",
        "path_to_tax = \"../../data/u1_subramanian14/taxonomy_subr14.qza\"\n",
        "\n",
        "# define train size\n",
        "train_size = 0.8\n",
        "######## END USER INPUTS #####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load ritme experiment configuration\n",
        "config = _load_experiment_config(model_config_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Perform train-test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(448, 38) (448, 850)\n",
            "Train: (362, 888), Test: (86, 888)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/adamova/miniforge3/envs/ritme_model/lib/python3.10/site-packages/ritme/split_train_test.py:135: UserWarning: Provided feature table contains absolute instead of relative abundances. Hence, converting it to relative abundances...\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "md, ft = _load_data(path_to_md, path_to_ft)\n",
        "print(md.shape, ft.shape)\n",
        "\n",
        "train_val, test = split_train_test(\n",
        "    md,\n",
        "    ft,\n",
        "    stratify_by_column=config[\"stratify_by_column\"],\n",
        "    feature_prefix=config[\"feature_prefix\"],\n",
        "    train_size=train_size,\n",
        "    seed=config[\"seed_data\"],\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Find and evaluate optimal feature and model configuration with ritme"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div class=\"tuneStatus\">\n",
              "  <div style=\"display: flex;flex-direction: row\">\n",
              "    <div style=\"display: flex;flex-direction: column;\">\n",
              "      <h3>Tune Status</h3>\n",
              "      <table>\n",
              "<tbody>\n",
              "<tr><td>Current time:</td><td>2024-12-05 09:38:09</td></tr>\n",
              "<tr><td>Running for: </td><td>00:00:23.27        </td></tr>\n",
              "<tr><td>Memory:      </td><td>10.2/16.0 GiB      </td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "    </div>\n",
              "    <div class=\"vDivider\"></div>\n",
              "    <div class=\"systemInfo\">\n",
              "      <h3>System Info</h3>\n",
              "      Using AsyncHyperBand: num_stopped=0<br>Bracket: Iter 40.000: None | Iter 10.000: None<br>Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n",
              "    </div>\n",
              "    \n",
              "  </div>\n",
              "  <div class=\"hDivider\"></div>\n",
              "  <div class=\"trialStatus\">\n",
              "    <h3>Trial Status</h3>\n",
              "    <table>\n",
              "<thead>\n",
              "<tr><th>Trial name       </th><th>status    </th><th>loc            </th><th>bootstrap  </th><th>data_aggregation  </th><th>data_selection    </th><th style=\"text-align: right;\">  data_selection_t</th><th>data_transform  </th><th style=\"text-align: right;\">  max_depth</th><th>max_features  </th><th style=\"text-align: right;\">          min_impurity_decreas\n",
              "e</th><th style=\"text-align: right;\">  min_samples_leaf</th><th style=\"text-align: right;\">  min_samples_split</th><th style=\"text-align: right;\">            min_weight_fraction_\n",
              "leaf</th><th>model  </th><th style=\"text-align: right;\">  n_estimators</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  rmse_val</th><th style=\"text-align: right;\">  rmse_train</th><th style=\"text-align: right;\">  r2_val</th></tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr><td>train_rf_4f054697</td><td>TERMINATED</td><td>127.0.0.1:97793</td><td>False      </td><td>                  </td><td>variance_threshold</td><td style=\"text-align: right;\">       6.16517e-05</td><td>                </td><td style=\"text-align: right;\">           </td><td>              </td><td style=\"text-align: right;\">0.118351 </td><td style=\"text-align: right;\">        0.0162992 </td><td style=\"text-align: right;\">         0.00188113</td><td style=\"text-align: right;\">0.000369536</td><td>rf     </td><td style=\"text-align: right;\">           120</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.63906 </td><td style=\"text-align: right;\">   3.03335</td><td style=\"text-align: right;\">     1.13039</td><td style=\"text-align: right;\">0.768043</td></tr>\n",
              "<tr><td>train_rf_2c0418a4</td><td>TERMINATED</td><td>127.0.0.1:97804</td><td>False      </td><td>                  </td><td>variance_threshold</td><td style=\"text-align: right;\">       2.23264e-05</td><td>                </td><td style=\"text-align: right;\">         16</td><td>              </td><td style=\"text-align: right;\">0.0165222</td><td style=\"text-align: right;\">        0.00466977</td><td style=\"text-align: right;\">         0.025424  </td><td style=\"text-align: right;\">0.000452001</td><td>rf     </td><td style=\"text-align: right;\">            80</td><td style=\"text-align: right;\">     1</td><td style=\"text-align: right;\">        0.640354</td><td style=\"text-align: right;\">   2.87253</td><td style=\"text-align: right;\">     1.10773</td><td style=\"text-align: right;\">0.791987</td></tr>\n",
              "</tbody>\n",
              "</table>\n",
              "  </div>\n",
              "</div>\n",
              "<style>\n",
              ".tuneStatus {\n",
              "  color: var(--jp-ui-font-color1);\n",
              "}\n",
              ".tuneStatus .systemInfo {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus td {\n",
              "  white-space: nowrap;\n",
              "}\n",
              ".tuneStatus .trialStatus {\n",
              "  display: flex;\n",
              "  flex-direction: column;\n",
              "}\n",
              ".tuneStatus h3 {\n",
              "  font-weight: bold;\n",
              "}\n",
              ".tuneStatus .hDivider {\n",
              "  border-bottom-width: var(--jp-border-width);\n",
              "  border-bottom-color: var(--jp-border-color0);\n",
              "  border-bottom-style: solid;\n",
              "}\n",
              ".tuneStatus .vDivider {\n",
              "  border-left-width: var(--jp-border-width);\n",
              "  border-left-color: var(--jp-border-color0);\n",
              "  border-left-style: solid;\n",
              "  margin: 0.5em 1em 0.5em 1em;\n",
              "}\n",
              "</style>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train_rf pid=97793)\u001b[0m Train: (276, 81), Test: (86, 81)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: Currently logged in as: adamovanja (ritme). Use `wandb login --relogin` to force relogin\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: Tracking run with wandb version 0.18.7\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: Run data is saved locally in /private/tmp/ray/session_2024-12-05_09-37-43_101217_97729/artifacts/2024-12-05_09-37-46/rf/driver_artifacts/train_rf_4f054697_1_bootstrap=False,data_aggregation=None,data_selection=variance_threshold,data_selection_t=0.0001,data_transform_2024-12-05_09-37-46/wandb/run-20241205_093759-4f054697\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: Syncing run train_rf_4f054697\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: \u2b50\ufe0f View project at https://wandb.ai/ritme/u1_rf_config\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: \ud83d\ude80 View run at https://wandb.ai/ritme/u1_rf_config/runs/4f054697\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:                                                                                \n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: \n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: Run history:\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: iterations_since_restore \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:              nb_features \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:                 r2_train \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:                   r2_val \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:               rmse_train \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:                 rmse_val \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:       time_since_restore \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:         time_this_iter_s \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:             time_total_s \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:                timestamp \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:       training_iteration \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: \n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: Run summary:\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: iterations_since_restore 1\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:              nb_features 43\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:                 r2_train 0.96059\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:                   r2_val 0.76804\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:               rmse_train 1.13039\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:                 rmse_val 3.03335\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:       time_since_restore 0.63906\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:         time_this_iter_s 0.63906\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:             time_total_s 0.63906\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:                timestamp 1733387876\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb:       training_iteration 1\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: \n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: \ud83d\ude80 View run train_rf_4f054697 at: https://wandb.ai/ritme/u1_rf_config/runs/4f054697\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: \u2b50\ufe0f View project at: https://wandb.ai/ritme/u1_rf_config\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[36m(_WandbLoggingActor pid=97803)\u001b[0m wandb: Find logs at: ./wandb/run-20241205_093759-4f054697/logs\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[36m(train_rf pid=97804)\u001b[0m Train: (276, 112), Test: (86, 112)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-12-05 09:38:09,624\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/adamova/Documents/projects/14_LM1/ritme_examples/use_cases/u1_amplicon_age_prediction/u1_rf_best_model/u1_rf_config/rf' in 0.0221s.\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: Currently logged in as: adamovanja (ritme). Use `wandb login --relogin` to force relogin\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: Tracking run with wandb version 0.18.7\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: Run data is saved locally in /private/tmp/ray/session_2024-12-05_09-37-43_101217_97729/artifacts/2024-12-05_09-37-46/rf/driver_artifacts/train_rf_2c0418a4_2_bootstrap=False,data_aggregation=None,data_selection=variance_threshold,data_selection_t=0.0000,data_transform_2024-12-05_09-37-56/wandb/run-20241205_093810-2c0418a4\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: Syncing run train_rf_2c0418a4\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: \u2b50\ufe0f View project at https://wandb.ai/ritme/u1_rf_config\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: \ud83d\ude80 View run at https://wandb.ai/ritme/u1_rf_config/runs/2c0418a4\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:                                                                                \n",
            "2024-12-05 09:38:13,811\tINFO tune.py:1041 -- Total run time: 27.50 seconds (23.24 seconds for the tuning loop).\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: \n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: Run history:\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: iterations_since_restore \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:              nb_features \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:                 r2_train \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:                   r2_val \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:               rmse_train \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:                 rmse_val \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:       time_since_restore \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:         time_this_iter_s \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:             time_total_s \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:                timestamp \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:       training_iteration \u2581\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: \n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: Run summary:\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: iterations_since_restore 1\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:              nb_features 74\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:                 r2_train 0.96215\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:                   r2_val 0.79199\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:               rmse_train 1.10773\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:                 rmse_val 2.87253\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:       time_since_restore 0.64035\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:         time_this_iter_s 0.64035\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:             time_total_s 0.64035\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:                timestamp 1733387887\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb:       training_iteration 1\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: \n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: \ud83d\ude80 View run train_rf_2c0418a4 at: https://wandb.ai/ritme/u1_rf_config/runs/2c0418a4\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: \u2b50\ufe0f View project at: https://wandb.ai/ritme/u1_rf_config\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
            "\u001b[36m(_WandbLoggingActor pid=97833)\u001b[0m wandb: Find logs at: ./wandb/run-20241205_093810-2c0418a4/logs\n"
          ]
        }
      ],
      "source": [
        "# find best model config\n",
        "tax = _load_taxonomy(path_to_tax)\n",
        "phylo = _load_phylogeny(path_to_phylo)\n",
        "\n",
        "best_model_dict, path_to_exp = find_best_model_config(\n",
        "    config, train_val, tax, phylo, path_store_model_logs=\"u1_rf_best_model\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluate feature and model configuration used by original paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rmse_train</th>\n",
              "      <th>r2_train</th>\n",
              "      <th>rmse_test</th>\n",
              "      <th>r2_test</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>rf</th>\n",
              "      <td>1.701717</td>\n",
              "      <td>0.916059</td>\n",
              "      <td>3.724957</td>\n",
              "      <td>0.624255</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    rmse_train  r2_train  rmse_test   r2_test\n",
              "rf    1.701717  0.916059   3.724957  0.624255"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "metrics = evaluate_tuned_models(best_model_dict, config, train_val, test)\n",
        "metrics"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ritme_model",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
