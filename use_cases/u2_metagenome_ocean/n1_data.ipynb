{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Usecase 2: Ocean temperature prediction data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook prepares the dataset for the ocean temperature usecase following the general data preparation approach outlined in [the original publication by Sunagawa et al. 2015](https://www.science.org/doi/10.1126/science.1261359). It can be run in the following conda environment:\n",
        "\n",
        "This notebook can be run in the following conda environment (last command must be launched from root of this repos):\n",
        "```shell\n",
        "mamba env create -f environment_prep_data.yml\n",
        "conda activate ritme_examples_prep_data\n",
        "pip install -e .\n",
        "qiime dev refresh-cache\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import subprocess\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import qiime2 as q2\n",
        "import skbio\n",
        "from qiime2 import Artifact\n",
        "from skbio import TreeNode\n",
        "\n",
        "from src.meta_fetch import fetch_mitag_metadata\n",
        "from src.seq_fetch_n_process import fetch_mitag_otus\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "######## USER INPUTS ########\n",
        "# where to save all the data\n",
        "destination_folder = \"../../data/u2_tara_ocean\"\n",
        "# URL to metadata\n",
        "url_metadata = \"https://ocean-microbiome.embl.de/data/OM.CompanionTables.xlsx\"\n",
        "# URL to otu counts\n",
        "url_otu_counts = (\n",
        "    \"https://ocean-microbiome.embl.de/data/miTAG.taxonomic.profiles.release.tsv.gz\"\n",
        ")\n",
        "######## END USER INPUTS #####"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch and process metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fetch_mitag_metadata(destination_folder, url_metadata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# get tabs W1: sea basins for stratification from OM.CompanionTables\n",
        "md_w1 = pd.read_excel(\n",
        "    \"../../data/u2_tara_ocean/OM.CompanionTables.xlsx\", sheet_name=\"Table W1\"\n",
        ")\n",
        "\n",
        "# rename sample_id column and set as index\n",
        "sample_id = [x for x in md_w1.columns if x.startswith(\"Sample label\")]\n",
        "md_w1.rename(columns={sample_id[0]: \"sample_id\"}, inplace=True)\n",
        "md_w1.rename(columns={\"PANGAEA sample identifier\": \"PANGAEA Sample ID\"}, inplace=True)\n",
        "\n",
        "# rename sea basin column and select\n",
        "ocean_col = [x for x in md_w1.columns if x.startswith(\"Ocean and sea regions\")]\n",
        "md_w1.rename(columns={ocean_col[0]: \"ocean_basin\"}, inplace=True)\n",
        "\n",
        "# add potential covariates to also consider for modelling\n",
        "sampling_depth_col = [x for x in md_w1.columns if x.startswith(\"Sampling depth\")]\n",
        "md_w1.rename(columns={sampling_depth_col[0]: \"sampling_depth_m\"}, inplace=True)\n",
        "\n",
        "env_ft_col = [x for x in md_w1.columns if x.startswith(\"Environmental Feature\")]\n",
        "md_w1.rename(columns={env_ft_col[0]: \"env_feature\"}, inplace=True)\n",
        "\n",
        "lat_col = [x for x in md_w1.columns if x.startswith(\"Latitude\")]\n",
        "md_w1.rename(columns={lat_col[0]: \"latitude\"}, inplace=True)\n",
        "\n",
        "lon_col = [x for x in md_w1.columns if x.startswith(\"Longitude\")]\n",
        "md_w1.rename(columns={lon_col[0]: \"longitude\"}, inplace=True)\n",
        "\n",
        "\n",
        "md_selected = md_w1[\n",
        "    [\n",
        "        \"sample_id\",\n",
        "        \"PANGAEA Sample ID\",\n",
        "        \"ocean_basin\",\n",
        "        \"sampling_depth_m\",\n",
        "        \"env_feature\",\n",
        "        \"latitude\",\n",
        "        \"longitude\",\n",
        "    ]\n",
        "].copy()\n",
        "md_selected.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "md_w8 = pd.read_excel(\n",
        "    \"../../data/u2_tara_ocean/OM.CompanionTables.xlsx\", sheet_name=\"Table W8\"\n",
        ")\n",
        "temp_col = [x for x in md_w8.columns if \"temperature\" in x.lower()]\n",
        "md_w8.rename(columns={temp_col[0]: \"temperature_mean_degc\"}, inplace=True)\n",
        "md_w8_selected = md_w8[[\"PANGAEA Sample ID\", \"temperature_mean_degc\"]].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# merge\n",
        "md_merged = pd.merge(md_selected, md_w8_selected, how=\"inner\", on=\"PANGAEA Sample ID\")\n",
        "md_merged.set_index(\"sample_id\", inplace=True)\n",
        "# drop column PANGAEA Sample ID\n",
        "md_merged.drop(columns=\"PANGAEA Sample ID\", inplace=True)\n",
        "md_merged.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch and process sequences & taxonomy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "OTU counts derived from miTAG sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fetch raw count data\n",
        "fetch_mitag_otus(destination_folder, url_otu_counts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Raw feature table to be used by *ritme*: `otu_table_tara_ocean.tsv`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mitag_df = pd.read_csv(\n",
        "    os.path.join(destination_folder, \"miTAG.taxonomic.profiles.release.tsv\"), sep=\"\\t\"\n",
        ")\n",
        "mitag_df.rename(columns={\"OTU.rep\": \"Feature ID\"}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract only feature table & save\n",
        "cols_to_extract = [\n",
        "    col\n",
        "    for col in mitag_df.columns\n",
        "    if col.startswith(\"Feature ID\") or col.startswith(\"TARA\")\n",
        "]\n",
        "\n",
        "ft_df = mitag_df[cols_to_extract]\n",
        "ft_df.set_index(\"Feature ID\", inplace=True)\n",
        "ft_df = ft_df.T\n",
        "ft_df.columns.name = None\n",
        "\n",
        "# save to file\n",
        "ft_df.to_csv(os.path.join(destination_folder, \"otu_table_tara_ocean.tsv\"), sep=\"\\t\")\n",
        "\n",
        "ft_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Feature table for publication-like modelling: `otu_table_tara_ocean_proc` with these additional steps:\n",
        "* \"We applied an additional low-abundance filter, which removed features whose relative abundance did not exceed 0.0001 in any sample.\" (1)\n",
        "* \"we applied a logarithmic transformation to relative abundances using the function log10(x + x0), where x is the original relative abundance and x0 is a small constant, and x0 < min(x).\" (2)\n",
        "* \"Compositional data (see above) were normalized to ranks across samples and then used to learn a regression model to predict environmental measures.\" (3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (1) low abundance filtering of features\n",
        "# create relative abundances\n",
        "ft_df_rel = ft_df.apply(lambda row: row / row.sum(), axis=1)\n",
        "# remove features with max abundance < 0.0001\n",
        "print(ft_df_rel.shape)\n",
        "ft_df_rel_pub = ft_df_rel.loc[:, (ft_df_rel.max(axis=0) >= 0.0001).values]\n",
        "ft_df_rel_pub.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (2) log transformation of relative abundances\n",
        "PSEUDOCOUNT = 0.000001\n",
        "ft_df_rel_pub_log = ft_df_rel_pub.apply(\n",
        "    lambda x: x.apply(lambda y: np.log(y + PSEUDOCOUNT))\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# (3) normalize compositional data to ranks across samples (wouldn't necessarily require log transform before - results same)\n",
        "ft_df_rel_pub_log_ranked = ft_df_rel_pub_log.rank(axis=1, ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save to file\n",
        "ft_df_rel_pub_log_ranked.to_csv(\n",
        "    os.path.join(destination_folder, \"otu_table_tara_ocean_proc.tsv\"),\n",
        "    sep=\"\\t\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Extract taxonomy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# extract taxonomy table & save\n",
        "cols_for_tax = [\n",
        "    col\n",
        "    for col in mitag_df.columns\n",
        "    if col.startswith(\"Feature ID\") or not col.startswith(\"TARA\")\n",
        "]\n",
        "tax_df = mitag_df[cols_for_tax]\n",
        "tax_df.set_index(\"Feature ID\", inplace=True)\n",
        "\n",
        "# replace empty space with \"_\"\n",
        "tax_cols = [\"Domain\", \"Phylum\", \"Class\", \"Order\", \"Family\", \"Genus\"]\n",
        "tax_df[tax_cols] = tax_df[tax_cols].apply(lambda col: col.str.replace(\" \", \"_\"))\n",
        "\n",
        "# compress taxonomy info into \"Taxon\" column with prefixes\n",
        "prefixes = [\"k__\", \"p__\", \"c__\", \"o__\", \"f__\", \"g__\"]\n",
        "\n",
        "tax_df.loc[:, \"Taxon\"] = tax_df.apply(\n",
        "    lambda row: \"; \".join(\n",
        "        [\n",
        "            f\"{pre}{row[col]}\"\n",
        "            for pre, col in zip(prefixes, tax_cols)\n",
        "            if pd.notna(row[col])\n",
        "        ]\n",
        "    ),\n",
        "    axis=1,\n",
        ")\n",
        "\n",
        "# save to file\n",
        "tax_df_to_save = tax_df[[\"Taxon\"]].copy()\n",
        "tax_art = q2.Artifact.import_data(\"FeatureData[Taxonomy]\", tax_df_to_save)\n",
        "tax_art.save(os.path.join(destination_folder, \"taxonomy_tara_ocean.qza\"))\n",
        "\n",
        "tax_df_to_save.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Build phylogenetic tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "command = f\"../../src/create_phylogeny_u2.sh {destination_folder} 3\"\n",
        "subprocess.run(command, shell=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Remove taxonomic information from leaves and add unclassified node\n",
        "\n",
        "tree_file = os.path.join(destination_folder, \"fasttree_tree_rooted_suna15.qza\")\n",
        "file_out = tree_file.replace(\"rooted_\", \"rooted_proc_\")\n",
        "if os.path.exists(file_out):\n",
        "    print(f\"Processed tree file {file_out} already exists. Skipping tree processing.\")\n",
        "else:\n",
        "    phylogeny = q2.Artifact.load(tree_file)\n",
        "\n",
        "    tree = phylogeny.view(skbio.TreeNode)\n",
        "\n",
        "    # rename - removing tax info from leaves\n",
        "    for node in tree.tips():\n",
        "        # Extract the desired part of the node name using a regular expression\n",
        "        match = re.match(r\"([A-Za-z0-9_\\.]+)\\s+.*\", node.name)\n",
        "        if match:\n",
        "            # Update the node name with the extracted part\n",
        "            node.name = match.group(1)\n",
        "    # add unclassified node\n",
        "    node_unclassified = TreeNode(name=\"unclassified\", length=1.0)\n",
        "    tree.extend([node_unclassified])\n",
        "\n",
        "    phylogeny_renamed = Artifact.import_data(\"Phylogeny[Rooted]\", tree)\n",
        "    phylogeny_renamed.save(file_out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Subset metadata according to feature table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "md_index = md_merged.index.tolist()\n",
        "ft_df_index = ft_df.index.tolist()\n",
        "\n",
        "print(md_merged.shape)\n",
        "md_subset = md_merged.loc[ft_df.index]\n",
        "\n",
        "path_to_md = os.path.join(destination_folder, \"md_tara_ocean.tsv\")\n",
        "md_subset.to_csv(path_to_md, sep=\"\\t\")\n",
        "md_subset.shape"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ritme_examples_prep_data",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.23"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
