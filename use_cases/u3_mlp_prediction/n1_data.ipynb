{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Usecase 3: Microbiome load prediction data preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This notebook prepares the dataset for the microbiome load prediction usecase following the general data preparation approach outlined in [the original publication by Nishijima et al. 2024](10.1016/j.cell.2024.10.022). It can be run in the following conda environment:\n",
        "\n",
        "This notebook can be run in the following conda environment:\n",
        "```shell\n",
        "mamba env create -f environment_prep_data.yml\n",
        "conda activate ritme_examples_prep_data\n",
        "pip install -e .\n",
        "qiime dev refresh-cache\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import qiime2 as q2\n",
        "\n",
        "from src.process_u3 import process_feature_table\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Fetch data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "shellscript"
        }
      },
      "outputs": [],
      "source": [
        "! ./../../src/fetch_mlp_data.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "path_to_data = \"../../data/u3_mlp_nishijima24\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Galaxy dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "galaxy_md = pd.read_csv(f\"{path_to_data}/GALAXY_load.tsv\", sep=\"\\t\", index_col=0)\n",
        "galaxy_md[\"count_log10\"] = np.log10(galaxy_md[\"count\"])\n",
        "\n",
        "print(galaxy_md.shape)\n",
        "galaxy_md.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save to disk\n",
        "galaxy_md.to_csv(f\"{path_to_data}/md_galaxy.tsv\", sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "galaxy_motus = process_feature_table(path_to_data, \"GALAXY_mOTUs_v25\")\n",
        "print(galaxy_motus.shape)\n",
        "\n",
        "# save to disk\n",
        "galaxy_motus.to_csv(f\"{path_to_data}/galaxy_otu_table.tsv\", sep=\"\\t\")\n",
        "galaxy_motus.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# are they relative abundances?\n",
        "assert galaxy_motus.sum(axis=1).round(3).eq(1.0).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check are all sample IDs present in metadata?\n",
        "assert len([x for x in galaxy_motus.index if x not in galaxy_md.index]) == 0\n",
        "assert len([x for x in galaxy_md.index if x not in galaxy_motus.index]) == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Taxonomy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "taxonomy_mapping = pd.read_csv(\n",
        "    \"../../data/u3_mlp_nishijima24/motus2GTDB.txt\", sep=\"\\t\", index_col=0\n",
        ")\n",
        "\n",
        "# remove empty spaces from column values\n",
        "for col in taxonomy_mapping.columns:\n",
        "    taxonomy_mapping[col] = taxonomy_mapping[col].str.replace(\" \", \"_\")\n",
        "\n",
        "taxonomy_mapping.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "prefix_matching = {\n",
        "    \"Kingdom\": \"k__\",\n",
        "    \"Phylum\": \"p__\",\n",
        "    \"Class\": \"c__\",\n",
        "    \"Order\": \"o__\",\n",
        "    \"Family\": \"f__\",\n",
        "    \"Genus\": \"g__\",\n",
        "    \"Species\": \"s__\",\n",
        "}\n",
        "\n",
        "tax_df = pd.DataFrame(index=taxonomy_mapping.index)\n",
        "tax_df[\"Taxon\"] = taxonomy_mapping.apply(\n",
        "    lambda x: \"; \".join(\n",
        "        [f\"{prefix_matching[k]}{v}\" for k, v in x.items() if not pd.isna(v)]\n",
        "    ),\n",
        "    axis=1,\n",
        ")\n",
        "# create correct index\n",
        "tax_df.index = [f\"ref_mOTU_v25_{x}\" for x in tax_df.index.tolist()]\n",
        "tax_df.index.name = \"Feature ID\"\n",
        "\n",
        "# add unclassified\n",
        "tax_df.loc[\n",
        "    \"unclassified\", \"Taxon\"\n",
        "] = \"k__undef; p__undef; c__undef; o__undef; f__undef; g__undef; s__undef\"\n",
        "tax_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save to disk\n",
        "tax_art = q2.Artifact.import_data(\"FeatureData[Taxonomy]\", tax_df)\n",
        "tax_art.save(f\"{path_to_data}/u3_taxonomy.qza\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No phylogeny tree can be constructed since we do not have the nucleotide sequences of these mOTUs -> no trac trainable"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Metacardis dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Metadata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metacardis_md = pd.read_csv(\n",
        "    f\"{path_to_data}/MetaCardis_load.tsv\", sep=\"\\t\", index_col=0\n",
        ")\n",
        "\n",
        "# according to publication perform log10 transformation\n",
        "metacardis_md[\"count_log10\"] = np.log10(metacardis_md[\"count\"])\n",
        "\n",
        "print(metacardis_md.shape)\n",
        "metacardis_md.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# save to disk\n",
        "metacardis_md.to_csv(f\"{path_to_data}/md_metacardis.tsv\", sep=\"\\t\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Feature table"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "metacardis_motus = process_feature_table(path_to_data, \"MetaCardis_mOTUs_v25\")\n",
        "print(metacardis_motus.shape)\n",
        "\n",
        "# save to disk\n",
        "metacardis_motus.to_csv(f\"{path_to_data}/metacardis_otu_table.tsv\", sep=\"\\t\")\n",
        "\n",
        "metacardis_motus.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# are they relative abundances?\n",
        "assert metacardis_motus.sum(axis=1).round(3).eq(1.0).all()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# check are all sample IDs present in metadata?\n",
        "assert len([x for x in metacardis_motus.index if x not in metacardis_md.index]) == 0\n",
        "assert len([x for x in metacardis_md.index if x not in metacardis_motus.index]) == 0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Taxonomy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "was already processed above as `tax_art` - same mapping can be used for both datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "No phylogeny tree can be constructed since we do not have the nucleotide sequences of these mOTUs -> no trac trainable"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ritme_examples_prep_amplicon",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
